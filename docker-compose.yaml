services:
  namenode:
    build: ./docker/hadoop
    container_name: namenode
    environment:
      - HADOOP_ROLE=namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - namenode_data:/hadoop/dfs/name
      - spark-binaries:/opt/spark
    networks:
      - hadoop

  datanode:
    build: ./docker/hadoop
    container_name: datanode
    environment:
      - HADOOP_ROLE=datanode
    depends_on:
      - namenode
    ports:
      - "9864:9864"
    volumes:
      - datanode_data:/hadoop/dfs/data
      - spark-binaries:/opt/spark
    networks:
      - hadoop

  resourcemanager:
    build: ./docker/hadoop
    container_name: resourcemanager
    environment:
      - HADOOP_ROLE=resourcemanager
    depends_on:
      - namenode
      - datanode
    volumes:
      - spark-binaries:/opt/spark
    ports:
      - "8088:8088"
    networks:
      - hadoop

  nodemanager:
    build: ./docker/hadoop
    environment:
      - HADOOP_ROLE=nodemanager
    depends_on:
      - resourcemanager
    volumes:
      - ./docker/hadoop/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
      - hadoop-logs:/opt/hadoop/logs
      - hadoop-tmp:/opt/hadoop/tmp
      - spark-binaries:/opt/spark
    networks:
      - hadoop
    deploy:
      replicas: 3


  spark-client:
    build: ./docker/spark
    container_name: spark-client
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    volumes:
      - ./scripts:/scripts
      - spark-binaries:/opt/spark
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - YARN_CONF_DIR=/opt/hadoop/etc/hadoop
    networks:
      - hadoop
    tty: true
    stdin_open: true
    command: bash

volumes:
  namenode_data:
  datanode_data:
  spark-binaries:
  hadoop-logs:
  hadoop-tmp:

networks:
  hadoop:
    driver: bridge
